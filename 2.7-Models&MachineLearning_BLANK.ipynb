{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f50eae-6f41-4b28-9488-b72c216aab4d",
   "metadata": {},
   "source": [
    "# 2.7 - Models and machine learning\n",
    "\n",
    "### Learning goals for today\n",
    "1. Understand how to fit models to data, and use those models to make predictions\n",
    "2. Use machine learning models to classify large datasets\n",
    "\n",
    "---\n",
    "### How to use this notebook during class\n",
    "- Follow along as we go\n",
    "- Use your **Cards** to indicate where you're at:\n",
    "    - A **ðŸŸ©Green card** means you are caught up with Max and **ready to help your classmates**\n",
    "    - A **ðŸŸ¥Red card** means you are stuck and need help\n",
    "- <span style='color:red;'>EXERCISE</span> â€” work on this problem by yourself, or try with a partner if you get stuck\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920cdde1-1041-4586-9de2-ccbc817e89ea",
   "metadata": {},
   "source": [
    "First let's import some libraries we will use today. Remember if you don't have a library installed you can pip install it with:\n",
    "\n",
    "%pip install *package_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487d9fb-4ba7-409a-9ba5-5781e2aef825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae98cceb-a919-441d-bd4b-55a061ecbbc8",
   "metadata": {},
   "source": [
    "## 1) Beak size inheritance - predictive models\n",
    "\n",
    "The Grants also collected data about beak size of parents and offspring finches. We'll use this data to introduce the idea of building predictive models for data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab016661-d85c-4621-80b4-ead9a702ac47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7683ced-7737-4b0f-a959-9155c2746d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d168076f-6482-42c5-80e9-a444b2312b1f",
   "metadata": {},
   "source": [
    "### <span style='color:red;'>EXERCISE 1</span>: Compute linear correlation coefficient  (5 min)\n",
    "\n",
    "Let's **describe** the relationship between these two using the linear correlation coefficient. Use scipy.stats.pearsonr to compute the linear correlation coefficient between parent and offpsring beak depth, and print it\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad74f9b-a1e0-4b28-98b1-b2f1bbb18b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5be398d9-ce45-4bc4-ba0d-74cba8417f1d",
   "metadata": {},
   "source": [
    "What if we want to **predict** one value given another - for that we need a **model**\n",
    "\n",
    "Today we'll use the **scikit-learn** library, which has lots of machine learning tools\n",
    "\n",
    "This looks like a linear relationship so we'll try a very simple linear model to predict offpsring beak depth\n",
    "\n",
    "If you  need to install it, do so with ...\n",
    "\n",
    "`%pip install scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99ff7d-b9ba-4b84-8ca3-f6c4dd8eb80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "089b83e6-6682-42f9-b1fb-75f56c10bddf",
   "metadata": {},
   "source": [
    "### Getting the data ready\n",
    "we need a features matrix, (by convention we'll call it X), which is shape = (n_samples, n_features), for us n_features will be 1\n",
    "\n",
    "and a values matrix (y), which will be length n_samples and is the thing we're trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f35f4-69e8-4719-b7d6-fa0559f74465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28950fa6-b59e-413e-a0e9-daa9b7c61b6c",
   "metadata": {},
   "source": [
    "The goal here is to build a linear model that can use parent beak depth (X) to predict offpsring beak depth (y). The basic steps are:\n",
    "1. Split the samples into training and testing data\n",
    "2. Define a model\n",
    "3. Fit the model (optimize)\n",
    "4. Use the model to predict the testing data\n",
    "5. Evaluate the performance (compare predictions vs. real test data) - Exercise\n",
    "\n",
    "Let's first write **pseudo-code**, then we'll fill it in with real code. A benefit of this strategy is that you can plan the approach without knowing all the syntax yet, and look up what syntax you are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf9be88-8f8a-4090-92c6-d30a301b288f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beed4d71-06c5-49b5-a81c-98c9e795827c",
   "metadata": {},
   "source": [
    "### <span style='color:red;'>EXERCISE 2</span>: Compute the fraction of explained variance  (10 min)\n",
    "\n",
    "Use google or your favorite LLM (UAlbany has a Copilot license) to figure out how to compute the fraction of variance explained by our model in sklearn. Computing this will require using y_test and y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4a553-8270-4073-a710-1c86b3f68771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performace: fraction of variance explained by the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52688a6d-483f-4b5c-8012-0e1b3e26dda4",
   "metadata": {},
   "source": [
    "In addition to quantifying overall performance, it's a good idea to examine the predictions compared to the true values, to see what your model is doing. We'll do that with two plots:\n",
    "1. Predicted vs. test values\n",
    "2. The difference between predicted and true values (\"residuals\") as a function of the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80d6c6-5a0e-49fe-a9f2-c9ee1f538593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs real values for test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1649ee2-c043-47e2-9fea-dd1f8898f969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "433cdc4e-2c4c-4343-a871-aaefb3e63640",
   "metadata": {},
   "source": [
    "There is no clear relationship between the predicted values and the residuals, which is good. It means our model isn't systematically wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e36b6a-36d2-42a3-bbfe-53a5ae748ab8",
   "metadata": {},
   "source": [
    "### Adding another feature\n",
    "We also have information about the species of the parent/offspring pair - let's see if we can provide this information to the model to see if it helps its predictions.\n",
    "\n",
    "Conceptually, we want to use **two** features now to predict `offspring_beak_depth`:\n",
    "\n",
    "1. `parent_beak_depth`\n",
    "2. `species`\n",
    "\n",
    "But (1) is a number, and (2) is a category. How do we train a model on a combination of numbers and categories? One strategy is called **one-hot encoding** where we have a new feature for each category, and each sample has a 1 for its category and 0s everywhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd9b4c2-30ac-4c4e-b3cb-8c9d91e23d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847fdfb8-9dab-4f50-8046-1a48bdb49265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "220257ff-5d82-47d7-8d42-574e72971634",
   "metadata": {},
   "source": [
    "Training the model on this new feature set looks a lot like the code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f635774-4d41-4421-b839-ecc5f99de2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c4c22b6-fdf2-41f5-b64f-c04f48fb3f8e",
   "metadata": {},
   "source": [
    "## 2) Beak size dataset - machine learning classifier\n",
    "\n",
    "Let's re-load our original beak size dataframe, and look at the distribution again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0f3b9-2a07-4e9a-beef-e37ed68ab47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "537ca665-3b09-4144-8297-148f4f260e57",
   "metadata": {},
   "source": [
    "The beak size distributions are pretty non-overlapping, which suggests that we should be able to predict the species based on beak measurements alone. One way to do this is with a classifier model.\n",
    "\n",
    "We are going to use a simple, commmon model called a **Support Vector Machine (SVM)**.\n",
    "\n",
    "sklearn has an implementation of an SVM for classification called a **Support Vector Classifier (SVC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb2ba4-9236-4df0-bcda-df08513865ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "582795a0-3ddf-4d8e-af27-e124ec9eabb9",
   "metadata": {},
   "source": [
    "### Getting the data ready\n",
    "we need a features matrix, (by convention we'll call it X), which is shape = (n_samples, n_features), for us n_features will be 2\n",
    "and a values matrix (y), which will be length n_samples and just be the species name for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795450b5-d4bc-4e71-a5bf-8524d1ab6648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b344fadd-5e25-42f1-8340-e564f5391184",
   "metadata": {},
   "source": [
    "The steps for doing this kind of classification are:\n",
    "1. Split the data into training data and testing data\n",
    "2. Fit the model\n",
    "3. Predict some testing data and evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798f6c2-a4cf-4806-9cc5-4d6575411e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92a6a8fe-66a1-45be-9191-31fa68f593c1",
   "metadata": {},
   "source": [
    "### Visualizing the decision boundary\n",
    "SVM works by forming a decision boundary in the feature space that splits points into each class. In this case the feature space is just two dimensional, so it's easy to visualize. But in principle this can be a high dimensional feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd974e-8cc7-4122-a999-3549f66bfe0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53c49bed-13db-4a88-bf9a-68abaa645966",
   "metadata": {},
   "source": [
    "What features is the model using to predict species? We have a sense that it's going to be the beak length, since that's the axis that separates the groups better. We can quantify this using a permutation test, and sklearn has a function that does this for us called **permutation_importance**\n",
    "\n",
    "What this function is doing is, for each feature, scrambling the features relative to the labels and re-testing, to see how well the model does when one feature at a time is randomized. The permutation importance for a feature is related to how much model performance drops when you randomize that feature.\n",
    "\n",
    "Remember the first feaure was beak length, and the second was beak depth\n",
    "\n",
    "`X = beak_df[['beak length (mm)', 'beak depth (mm)']].values`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c1f64-c6cd-41c4-88b3-0614fcca061f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e04c851-86dc-495c-9c55-0dac3c2daa37",
   "metadata": {},
   "source": [
    "### <span style='color:red;'>EXERCISE 3</span>: Test how well the model does with fewer features  (15 min)\n",
    "\n",
    "Modify the SVC code above to measure prediction accuracy using just one or the other feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8639827-941c-49e5-b6b3-6b041f35042d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954de34-c71d-4fee-9605-9637ada860ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abio558",
   "language": "python",
   "name": "abio558"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
